% This file was created with JabRef 2.7b.
% Encoding: UTF-8

@MISC{Azimi2009,
  author = {Reza Azimi},
  title = {Hardware Performance Monitoring},
  year = {2009},
  owner = {urs},
  timestamp = {2011.07.15},
  url = {www.cse.shirazu.ac.ir/~azimi/perf88/lectures/Lect5-HardwarePerfMon.pdf}
}

@MISC{Eranian2010,
  author = {Stephane Eranian},
  title = {perf\_events status update},
  month = {8},
  year = {2010},
  owner = {urs},
  timestamp = {2011.07.13},
  url = {http://cscads.rice.edu/workshops/summer-2010/slides/performance-tools/perf_events_status_update.pdf/view}
}

@TECHREPORT{Faessler2011,
  author = {Urs Fässler},
  title = {perf file format},
  institution = {CERN},
  year = {2011},
  month = {9},
  owner = {urs},
  timestamp = {2011.09.01}
}

@MISC{Jarp2010,
  author = {Sverre Jarp},
  title = {Computer Architecture and Performance Tuning},
  month = {9},
  year = {2010},
  owner = {urs},
  timestamp = {2011.08.31},
  url = {http://indico.cern.ch/getFile.py/access?resId=1&materialId=slides&confId=36801}
}

@MISC{kernel.org2011,
  author = {kernel.org},
  title = {Linux kernel profiling with perf},
  month = {6},
  year = {2011},
  owner = {urs},
  timestamp = {2011.07.13},
  url = {https://perf.wiki.kernel.org/index.php/Tutorial}
}

@MISC{Kleen2011,
  author = {Andi Kleen},
  title = {Modern CPU Performance Analysis on Linux},
  month = {6},
  year = {2011},
  owner = {urs},
  timestamp = {2011.08.01}
}

@MISC{oprofile,
  author = {John Levon and Philippe Elie and Maynard Johnson and Suravee Suthikulpanit
	and Richard Purdie and Daniel Hansel and Robert Richter},
  title = {OProfile},
  year = {2011},
  owner = {urs},
  timestamp = {2011.07.14},
  url = {http://oprofile.sourceforge.net}
}

@TECHREPORT{Melo2010,
  author = {Arnaldo Carvalho de Melo},
  title = {The New Linux ’perf’ Tools},
  year = {2010},
  owner = {urs},
  timestamp = {2011.08.01},
  url = {http://vger.kernel.org/~acme/perf/lk2010-perf-paper.pdf}
}

@MISC{Nowak2011,
  author = {Andrzej Nowak},
  title = {CERN openlab Computer Architecture and Performance Tuning Workshop},
  year = {2011},
  owner = {urs},
  timestamp = {2011.09.01}
}

@TECHREPORT{Popescu2010,
  author = {Diana Andreea Popescu},
  title = {Performance monitoring of the software frameworks for the LHC experiments},
  institution = {CERN},
  year = {2010},
  month = {8},
  abstract = {This document presents the extraction, maintenance and performance
	monitoring of the latest benchmarks representative of the 4 major
	software experiment frameworks at CERN, namely ATLAS, ALICE, CMS
	and LHCb. The benchmarks contain all event processing steps. The
	performance monitoring tasks for the software experiments were carried
	using the Intel Performance Tuning Utility and perfmon.},
  owner = {urs},
  timestamp = {2011.07.08},
  url = {https://openlab-mu-internal.web.cern.ch/openlab-mu-internal/03_Documents/3_Technical_Documents/Technical_Reports/2010/Diana-Andreea_Popescu-Performance_monitoring_for_the_LHC_experiments.pdf}
}

@MISC{Weaver2011,
  author = {Vince Weaver},
  title = {The Unofficial Linux Perf Events Web-Page},
  year = {2011},
  owner = {urs},
  timestamp = {2011.07.13},
  url = {http://web.eecs.utk.edu/~vweaver1/projects/perf-events/}
}

@MISC{Weaver2010,
  author = {Vincent M. Weaver and Jack Dongarra},
  title = {Can Hardware Performance Counters Produce Expected, Deterministic
	Results?},
  month = {12},
  year = {2010},
  abstract = {Experiments involving hardware performance counters would ideally
	have deterministic results when run in strictly controlled environments.
	In practice counters that shouldbe deterministic (such as retired
	instructions) show variation from run to run on the x86 64 architecture.
	This causes difficulties when undertaking certain performance-counter
	related tasks, such as simulator validation and performance analysis.
	These variations also impede software-based deterministic thread-interleaving,
	useful for debugging and tuning multi-threaded workloads on modern
	CMP systems.
	
	We investigate a variety of x86 64 implementations (including DBI
	tools) and discover the sources of variations from expected count
	totals. The largest impact on retired instruction totals is due to
	the inclusion of hardware interrupt counts. This is difficult to
	compensate for, limiting the utility of the counters. In addition,
	counts generated by specific instructions can be counted differently
	across implementations, leading to cross-machine variations in aggregate
	counts.
	
	We briefly investigate ARM, IA64, POWER and SPARC systems and find
	that on these platforms the counts do not include hardware interrupts.
	Non-deterministic limitations to counter use may be a particular
	feature of the x86 64 architecture.
	
	We also apply our methodology to larger programs and find that run-to-run
	variation can be minimized, but it is difficult to determine known
	“good” reference counts for comparison.},
  owner = {urs},
  timestamp = {2011.07.15},
  url = {http://icl.cs.utk.edu/news_pub/submissions/fhpm2010_weaver.pdf}
}

@MISC{kvm,
  title = {Kernel-based Virtual Machine},
  owner = {urs},
  timestamp = {2011.07.29},
  url = {http://www.linux-kvm.org/page/Main_Page}
}

@MISC{virtualbox,
  title = {VirtualBox},
  owner = {urs},
  timestamp = {2011.07.29},
  url = {http://www.virtualbox.org/}
}

@MISC{pfmon2007,
  title = {Pfmon documentation},
  month = {10},
  year = {2007},
  owner = {urs},
  timestamp = {2011.07.13},
  url = {http://perfmon2.sourceforge.net/pfmon_usersguide.html}
}

@comment{jabref-meta: selector_publisher:}

@comment{jabref-meta: selector_author:}

@comment{jabref-meta: selector_journal:}

@comment{jabref-meta: selector_keywords:}

